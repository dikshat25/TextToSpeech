{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: librosa in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: torch in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: unidecode in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.8)\n",
      "Requirement already satisfied: deep-phonemizer in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.0.19)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (6.0.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (2.14.0)\n",
      "Requirement already satisfied: certifi>=2022.12.7 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (2024.12.14)\n",
      "Requirement already satisfied: wheel>=0.38.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (0.45.1)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (75.3.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from numba>=0.51.0->librosa) (8.5.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.38.0->deep-phonemizer) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (1.70.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (3.7)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (5.29.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (3.0.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->deep-phonemizer) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->deep-phonemizer) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->deep-phonemizer) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas librosa torch torchaudio matplotlib unidecode deep-phonemizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                               text  \\\n",
      "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
      "1  LJ001-0002                     in being comparatively modern.   \n",
      "2  LJ001-0003  For although the Chinese took impressions from...   \n",
      "3  LJ001-0004  produced the block books, which were the immed...   \n",
      "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
      "\n",
      "                                     normalized_text  \n",
      "0  Printing, in the only sense with which we are ...  \n",
      "1                     in being comparatively modern.  \n",
      "2  For although the Chinese took impressions from...  \n",
      "3  produced the block books, which were the immed...  \n",
      "4  the invention of movable metal letters in the ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"D:/vjti projects/TTS/\"\n",
    "\n",
    "metadata_path = f\"{dataset_path}/metadata.csv\"\n",
    "df = pd.read_csv(metadata_path, sep=\"|\", header=None, names=[\"ID\", \"text\", \"normalized_text\"])\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Printing, in the only sense with which we are ...   \n",
      "1                     in being comparatively modern.   \n",
      "2  For although the Chinese took impressions from...   \n",
      "3  produced the block books, which were the immed...   \n",
      "4  the invention of movable metal letters in the ...   \n",
      "\n",
      "                                        encoded_text  \n",
      "0  [27, 29, 20, 25, 31, 20, 25, 18, 6, 11, 20, 25...  \n",
      "1  [20, 25, 11, 13, 16, 20, 25, 18, 11, 14, 26, 2...  \n",
      "2  [17, 26, 29, 11, 12, 23, 31, 19, 26, 32, 18, 1...  \n",
      "3  [27, 29, 26, 15, 32, 14, 16, 15, 11, 31, 19, 1...  \n",
      "4  [31, 19, 16, 11, 20, 25, 33, 16, 25, 31, 20, 2...  \n"
     ]
    }
   ],
   "source": [
    "# text preprocessing character enncoding\n",
    "\n",
    "# Define character mapping\n",
    "symbols = \"_-!'(),.:;? abcdefghijklmnopqrstuvwxyz\"\n",
    "look_up = {s: i for i, s in enumerate(symbols)}\n",
    "symbols = set(symbols)\n",
    "\n",
    "# Function to encode text\n",
    "def text_to_sequence(text):\n",
    "    if isinstance(text, str):  # ensure the text is a string (handle NaN values)\n",
    "        text = text.lower()\n",
    "        return [look_up[s] for s in text if s in symbols]\n",
    "    return []  # for missing values\n",
    "\n",
    "# Apply encoding \n",
    "df[\"encoded_text\"] = df[\"text\"].apply(text_to_sequence)\n",
    "print(df[[\"text\", \"encoded_text\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Printing, in the only sense with which we are ...   \n",
      "1                     in being comparatively modern.   \n",
      "2  For although the Chinese took impressions from...   \n",
      "3  produced the block books, which were the immed...   \n",
      "4  the invention of movable metal letters in the ...   \n",
      "\n",
      "                               tacotron_encoded_text  \n",
      "0  [[27, 29, 20, 25, 31, 20, 25, 18, 6, 11, 20, 2...  \n",
      "1  [[20, 25, 11, 13, 16, 20, 25, 18, 11, 14, 26, ...  \n",
      "2  [[17, 26, 29, 11, 12, 23, 31, 19, 26, 32, 18, ...  \n",
      "3  [[27, 29, 26, 15, 32, 14, 16, 15, 11, 31, 19, ...  \n",
      "4  [[31, 19, 16, 11, 20, 25, 33, 16, 25, 31, 20, ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "\n",
    "processor = torchaudio.pipelines.TACOTRON2_WAVERNN_CHAR_LJSPEECH.get_text_processor()\n",
    "\n",
    "# Function to process text using the Tacotron2 processor\n",
    "def process_text(text):\n",
    "    if isinstance(text, str):  # Ensure text is a string to avoid NaN errors\n",
    "        processed, lengths = processor(text)\n",
    "        return processed.tolist()  # Convert tensor \n",
    "    return []  # for missing values\n",
    "\n",
    "# processing \n",
    "df[\"tacotron_encoded_text\"] = df[\"text\"].apply(process_text)\n",
    "print(df[[\"text\", \"tacotron_encoded_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13100, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Printing, in the only sense with which we are ...   \n",
      "1                     in being comparatively modern.   \n",
      "2  For although the Chinese took impressions from...   \n",
      "3  produced the block books, which were the immed...   \n",
      "4  the invention of movable metal letters in the ...   \n",
      "\n",
      "                               tacotron_encoded_text  \n",
      "0  [[27, 29, 20, 25, 31, 20, 25, 18, 6, 11, 20, 2...  \n",
      "1  [[20, 25, 11, 13, 16, 20, 25, 18, 11, 14, 26, ...  \n",
      "2  [[17, 26, 29, 11, 12, 23, 31, 19, 26, 32, 18, ...  \n",
      "3  [[27, 29, 26, 15, 32, 14, 16, 15, 11, 31, 19, ...  \n",
      "4  [[31, 19, 16, 11, 20, 25, 33, 16, 25, 31, 20, ...  \n"
     ]
    }
   ],
   "source": [
    "# text processing\n",
    "import torchaudio\n",
    "\n",
    "# Load Tacotron2 text processor\n",
    "processor = torchaudio.pipelines.TACOTRON2_WAVERNN_CHAR_LJSPEECH.get_text_processor()\n",
    "\n",
    "# Function to process text using the Tacotron2 processor\n",
    "def process_text(text):\n",
    "    if isinstance(text, str):  # Ensure text is a string to avoid NaN errors\n",
    "        processed, lengths = processor(text)\n",
    "        return processed.tolist()  # Convert tensor \n",
    "    return []  # for missing values\n",
    "\n",
    "# Apply processing to the 'text' column\n",
    "df[\"tacotron_encoded_text\"] = df[\"text\"].apply(process_text)\n",
    "print(df[[\"text\", \"tacotron_encoded_text\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-phonemizer\n",
      "  Downloading deep-phonemizer-0.0.19.tar.gz (29 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch>=1.2.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (2.4.1)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (4.67.1)\n",
      "Collecting PyYAML>=5.1 (from deep-phonemizer)\n",
      "  Downloading PyYAML-6.0.2-cp38-cp38-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tensorboard (from deep-phonemizer)\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: certifi>=2022.12.7 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deep-phonemizer) (2024.12.14)\n",
      "Collecting wheel>=0.38.0 (from deep-phonemizer)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting setuptools>=65.5.1 (from deep-phonemizer)\n",
      "  Using cached setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.2.0->deep-phonemizer) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.2.0->deep-phonemizer) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.2.0->deep-phonemizer) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.2.0->deep-phonemizer) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.2.0->deep-phonemizer) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.2.0->deep-phonemizer) (2024.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.38.0->deep-phonemizer) (0.4.6)\n",
      "Collecting absl-py>=0.4 (from tensorboard->deep-phonemizer)\n",
      "  Downloading absl_py-2.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->deep-phonemizer)\n",
      "  Downloading grpcio-1.70.0-cp38-cp38-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard->deep-phonemizer)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard->deep-phonemizer)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->deep-phonemizer)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (1.24.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (2.32.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->deep-phonemizer)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard->deep-phonemizer) (3.0.6)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard->deep-phonemizer)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard->deep-phonemizer)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from markdown>=2.6.8->tensorboard->deep-phonemizer) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->deep-phonemizer) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->deep-phonemizer) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\diksha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch>=1.2.0->deep-phonemizer) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\diksha\\appdata\\roaming\\python\\python38\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->deep-phonemizer) (3.20.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->deep-phonemizer)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->deep-phonemizer)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading PyYAML-6.0.2-cp38-cp38-win_amd64.whl (162 kB)\n",
      "Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.0-py3-none-any.whl (276 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.70.0-cp38-cp38-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 1.3/4.3 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.4/4.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: deep-phonemizer\n",
      "  Building wheel for deep-phonemizer (pyproject.toml): started\n",
      "  Building wheel for deep-phonemizer (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for deep-phonemizer: filename=deep_phonemizer-0.0.19-py3-none-any.whl size=33288 sha256=d72162f39b53e95903cdce94796ac177159e4c1ee07bc3548eab3a4c28daed52\n",
      "  Stored in directory: c:\\users\\diksha\\appdata\\local\\pip\\cache\\wheels\\c3\\67\\e0\\2a1a7ccdd237f5aa475e1b7bff6344a5a3aa506e66ce79b162\n",
      "Successfully built deep-phonemizer\n",
      "Installing collected packages: wheel, tensorboard-data-server, setuptools, PyYAML, pyasn1, oauthlib, grpcio, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard, deep-phonemizer\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 41.2.0\n",
      "    Uninstalling setuptools-41.2.0:\n",
      "      Successfully uninstalled setuptools-41.2.0\n",
      "Successfully installed PyYAML-6.0.2 absl-py-2.2.0 cachetools-5.5.2 deep-phonemizer-0.0.19 google-auth-2.38.0 google-auth-oauthlib-1.0.0 grpcio-1.70.0 markdown-3.7 oauthlib-3.2.2 pyasn1-0.6.1 pyasn1-modules-0.4.1 requests-oauthlib-2.0.0 rsa-4.9 setuptools-75.3.2 tensorboard-2.14.0 tensorboard-data-server-0.7.2 wheel-0.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diksha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\dp\\model\\model.py:306: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "c:\\Users\\Diksha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Printing, in the only sense with which we are ...   \n",
      "1                     in being comparatively modern.   \n",
      "2  For although the Chinese took impressions from...   \n",
      "3  produced the block books, which were the immed...   \n",
      "4  the invention of movable metal letters in the ...   \n",
      "\n",
      "                             tacotron_phoneme_tokens  \n",
      "0  [77, 78, 55, 67, 55, 68, 6, 11, 55, 67, 11, 39...  \n",
      "1  [55, 67, 11, 36, 59, 55, 68, 11, 64, 20, 66, 7...  \n",
      "2  [52, 24, 78, 11, 24, 65, 39, 69, 11, 39, 20, 1...  \n",
      "3  [77, 78, 20, 38, 87, 79, 81, 11, 39, 20, 11, 3...  \n",
      "4  [39, 20, 11, 55, 67, 91, 40, 67, 80, 20, 67, 1...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# Get the Tacotron2 phoneme-based processor\n",
    "bundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\n",
    "processor = bundle.get_text_processor()\n",
    "\n",
    "# Function to process text using Tacotron2 phoneme-based encoding\n",
    "def process_text(text):\n",
    "    if isinstance(text, str):  \n",
    "        with torch.inference_mode():  # Disable gradient tracking for inference\n",
    "            processed, lengths = processor(text)  # convert text to phoneme tokens\n",
    "        tokens = processed[0, : lengths[0]].tolist()  # convert tensor \n",
    "        return tokens\n",
    "    return [] \n",
    "\n",
    "# Apply processing to the 'text' column\n",
    "df[\"tacotron_phoneme_tokens\"] = df[\"text\"].apply(process_text)\n",
    "print(df[[\"text\", \"tacotron_phoneme_tokens\"]].head())\n",
    "df.to_csv(\"/TTs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 3000 files to D:/vjti projects/TTS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_folder = \"D:/vjti projects/TTS/wavs\"\n",
    "dest_folder = \"D:/vjti projects/TTS\"\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "files = sorted(os.listdir(src_folder))[:3000] \n",
    "\n",
    "# Move files\n",
    "for file in files:\n",
    "    shutil.move(os.path.join(src_folder, file), os.path.join(dest_folder, file))\n",
    "\n",
    "print(f\"Moved {len(files)} files to {dest_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Text to Spectrograms:   7%|▋         | 215/3000 [13:52<1:56:54,  2.52s/file]c:\\Users\\Diksha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchaudio\\models\\tacotron2.py:856: UserWarning: Reached max decoder steps. The generated spectrogram might not cover the whole transcript.\n",
      "  warnings.warn(\n",
      "Processing Text to Spectrograms: 100%|██████████| 3000/3000 [3:20:54<00:00,  4.02s/file]  \n",
      "c:\\Users\\Diksha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:604: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  val = np.array(val, copy=False)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3000,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m3000\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Text to Spectrograms\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     25\u001b[0m     spectrograms\u001b[38;5;241m.\u001b[39mappend(text_to_spectrogram(text))\n\u001b[1;32m---> 27\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2999\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspectrogram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m spectrograms  \u001b[38;5;66;03m# Store results only for first 3000 rows\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Save processed data\u001b[39;00m\n\u001b[0;32m     30\u001b[0m df\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m3000\u001b[39m]\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/vjti projects/TTS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Diksha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 849\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Diksha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1786\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key] \u001b[38;5;241m=\u001b[39m empty_value\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m# FIXME: GH#42099#issuecomment-864326014\u001b[39;00m\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key] \u001b[38;5;241m=\u001b[39m \u001b[43minfer_fill_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m new_indexer \u001b[38;5;241m=\u001b[39m convert_from_missing_indexer_tuple(\n\u001b[0;32m   1789\u001b[0m     indexer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m   1790\u001b[0m )\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(new_indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\Diksha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:604\u001b[0m, in \u001b[0;36minfer_fill_value\u001b[1;34m(val)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(val):\n\u001b[0;32m    603\u001b[0m     val \u001b[38;5;241m=\u001b[39m [val]\n\u001b[1;32m--> 604\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(val\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mval\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3000,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Load Tacotron2 phoneme-based processor\n",
    "device = torch.device(\"cpu\")  # Use CPU \n",
    "bundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\n",
    "processor = bundle.get_text_processor()\n",
    "tacotron2 = bundle.get_tacotron2().to(device)\n",
    "\n",
    "# Function to generate spectrograms from text\n",
    "def text_to_spectrogram(text):\n",
    "    if isinstance(text, str):  \n",
    "        with torch.inference_mode():\n",
    "            processed, lengths = processor(text)  # Convert text to phonemes\n",
    "            processed = processed.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            spec, _, _ = tacotron2.infer(processed, lengths)  # Generate spectrogram\n",
    "        return spec.to(device)  # Keep output on GPU\n",
    "    return None  \n",
    "\n",
    "# Process only the first 3000 texts\n",
    "spectrograms = []\n",
    "for text in tqdm(df[\"text\"][:3000], desc=\"Processing Text to Spectrograms\", unit=\"file\"):\n",
    "    spectrograms.append(text_to_spectrogram(text))\n",
    "\n",
    "df.loc[:2999, \"spectrogram\"] = spectrograms  # Store results only for first 3000 rows\n",
    "\n",
    "# Save processed data\n",
    "df.iloc[:3000].to_pickle(\"D:/vjti projects/TTS\")\n",
    "\n",
    "print(\"Processing completed! Data saved to processed_dataset_3000.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 700])\n"
     ]
    }
   ],
   "source": [
    "print(spectrograms[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"D:/vjti projects/TTS/processed_spectrograms.pkl\", \"wb\") as f:\n",
    "    pickle.dump([spec.cpu().numpy() for spec in spectrograms], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spectrogram\"] = pd.Series([spec.cpu().numpy() for spec in spectrograms], dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 80, 700])\n"
     ]
    }
   ],
   "source": [
    "print(type(spectrograms[0]), spectrograms[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spectrograms in file: 3000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the processed spectrograms\n",
    "with open(\"D:/vjti projects/TTS/processed_spectrograms.pkl\", \"rb\") as f:\n",
    "    spectrograms = pickle.load(f)\n",
    "\n",
    "# Check the number of spectrograms\n",
    "print(f\"Total spectrograms in file: {len(spectrograms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3000 spectrograms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Waveforms:   2%|▏         | 46/3000 [00:11<07:54,  6.23file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error processing spectrogram 44: min(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Waveforms:   7%|▋         | 205/3000 [00:49<11:29,  4.06file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error processing spectrogram 205: min(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Waveforms:  82%|████████▏ | 2447/3000 [17:31<03:11,  2.89file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error processing spectrogram 2446: min(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Waveforms: 100%|██████████| 3000/3000 [22:53<00:00,  2.18file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All waveforms processed and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import torchaudio\n",
    "from tqdm import tqdm  \n",
    "\n",
    "# File paths\n",
    "spectrograms_path = \"D:/vjti projects/TTS/processed_spectrograms.pkl\"\n",
    "waveforms_path = \"D:/vjti projects/TTS/generated_waveforms.pkl\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the Griffin-Lim vocoder\n",
    "bundle = torchaudio.pipelines.TACOTRON2_GRIFFINLIM_PHONE_LJSPEECH\n",
    "vocoder = bundle.get_vocoder().to(device)\n",
    "\n",
    "# Load spectrograms\n",
    "with open(spectrograms_path, \"rb\") as f:\n",
    "    spectrograms = pickle.load(f)\n",
    "\n",
    "# Try to load previously processed waveforms\n",
    "if os.path.exists(waveforms_path):\n",
    "    with open(waveforms_path, \"rb\") as f:\n",
    "        processed_waveforms = pickle.load(f)\n",
    "    print(f\"Loaded {len(processed_waveforms)} previously processed waveforms.\")\n",
    "else:\n",
    "    processed_waveforms = []\n",
    "\n",
    "# Start processing from where it left off\n",
    "start_idx = len(processed_waveforms)\n",
    "remaining = len(spectrograms) - start_idx\n",
    "print(f\"Processing {remaining} spectrograms...\")\n",
    "\n",
    "# Process spectrograms with a progress bar\n",
    "with torch.inference_mode():\n",
    "    for i in tqdm(range(start_idx, len(spectrograms)), desc=\"Generating Waveforms\", unit=\"file\"):\n",
    "        spec = torch.tensor(spectrograms[i]).to(device)  # Convert to tensor\n",
    "\n",
    "        # Ensure spectrogram is not empty before processing\n",
    "        if spec.numel() == 0:\n",
    "            print(f\"⚠ Skipping empty spectrogram at index {i}\")\n",
    "            continue\n",
    "\n",
    "        spec = spec.squeeze(0)  # Remove extra batch dimension if needed\n",
    "        spec_lengths = torch.tensor([spec.shape[-1]]).to(device)  \n",
    "        \n",
    "        try:\n",
    "            waveform, _ = vocoder(spec.unsqueeze(0), spec_lengths)\n",
    "            processed_waveforms.append(waveform.cpu())  # Move to CPU and store\n",
    "        except RuntimeError as e:\n",
    "            print(f\" Error processing spectrogram {i}: {e}\")\n",
    "            continue  \n",
    "\n",
    "        # Save progress every 100 samples\n",
    "        if (i + 1) % 100 == 0:\n",
    "            with open(waveforms_path, \"wb\") as f:\n",
    "                pickle.dump(processed_waveforms, f)\n",
    "\n",
    "# Final save\n",
    "with open(waveforms_path, \"wb\") as f:\n",
    "    pickle.dump(processed_waveforms, f)\n",
    "\n",
    "print(\" All waveforms processed and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram 44: Type=<class 'numpy.ndarray'>, Shape=(1, 80, 1)\n",
      "Spectrogram 205: Type=<class 'numpy.ndarray'>, Shape=(1, 80, 1)\n",
      "Spectrogram 2446: Type=<class 'numpy.ndarray'>, Shape=(1, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "# Find problematic spectrograms\n",
    "error_indices = [44, 205, 2446]\n",
    "\n",
    "for idx in error_indices:\n",
    "    spec = spectrograms[idx]\n",
    "    print(f\"Spectrogram {idx}: Type={type(spec)}, Shape={spec.shape if hasattr(spec, 'shape') else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Speech generated! Saved at: D:/vjti projects/TTS/ML/TTS/output5.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Tacotron2 (Text-to-Spectrogram) and Vocoder (Spectrogram-to-Speech)\n",
    "bundle = torchaudio.pipelines.TACOTRON2_GRIFFINLIM_PHONE_LJSPEECH\n",
    "processor = bundle.get_text_processor()\n",
    "tacotron2 = bundle.get_tacotron2().to(device)\n",
    "vocoder = bundle.get_vocoder().to(device)\n",
    "\n",
    "#  Enter your text here\n",
    "your_text = \"Hello, How are you?\"\n",
    "\n",
    "# Convert text to phonemes\n",
    "with torch.inference_mode():\n",
    "    processed, lengths = processor(your_text)\n",
    "    processed = processed.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "\n",
    "    # Generate spectrogram\n",
    "    spec, _, _ = tacotron2.infer(processed, lengths)\n",
    "\n",
    "# Generate waveform from spectrogram\n",
    "with torch.inference_mode():\n",
    "    waveform, _ = vocoder(spec, lengths)\n",
    "\n",
    "# Move waveform to CPU and convert to NumPy\n",
    "waveform = waveform.cpu().numpy().squeeze()\n",
    "\n",
    "# Save output as a .wav file\n",
    "output_path = \"D:/vjti projects/TTS/ML/TTS/output5.wav\"\n",
    "sf.write(output_path, waveform, samplerate=22050)\n",
    "\n",
    "print(f\" Speech generated! Saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total waveforms in file: 2997\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the generated waveforms\n",
    "with open(\"D:/vjti projects/TTS/generated_waveforms.pkl\", \"rb\") as f:\n",
    "    waveforms = pickle.load(f)\n",
    "\n",
    "# Print the number of waveforms\n",
    "print(f\"Total waveforms in file: {len(waveforms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(tacotron2.state_dict(), \"tacotron_model.pth\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
